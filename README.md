# Government Meeting Scraper

Robust web scraper for extracting meeting metadata from government websites with automatic retry, bot detection avoidance, and incremental saving.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       User Input                             â”‚
â”‚              (JSON with URLs & Date Range)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    scraper.py (CLI)                          â”‚
â”‚              Command-line interface handler                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ScraperEngine (core/engine.py)              â”‚
â”‚   â€¢ Orchestrates scraping workflow                          â”‚
â”‚   â€¢ Manages browser pool & HTTP requests                    â”‚
â”‚   â€¢ Handles retries & rate limiting                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                               â”‚
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser Manager    â”‚â”€â”€â”€â”€â”€â–¶â”‚   Site-Specific          â”‚
â”‚   (core/browser.py)  â”‚      â”‚   Extractors             â”‚
â”‚                      â”‚      â”‚   (extractors/*)         â”‚
â”‚ â€¢ Playwright setup   â”‚      â”‚                          â”‚
â”‚ â€¢ Stealth mode       â”‚      â”‚ â€¢ Uses browser to load   â”‚
â”‚ â€¢ Anti-detection     â”‚      â”‚ â€¢ Detects site type      â”‚
â”‚ â€¢ Auto-scroll        â”‚      â”‚ â€¢ Extracts meetings      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ â€¢ Parses dates           â”‚
                              â”‚ â€¢ Links classification   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    Data Validation      â”‚
                              â”‚                         â”‚
                              â”‚ â€¢ Date range filter     â”‚
                              â”‚ â€¢ URL verification      â”‚
                              â”‚ â€¢ Duplicate removal     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   JSON Output           â”‚
                              â”‚   (outputs/*.json)      â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features:**
- Sequential processing with incremental saving
- Automatic retry with exponential backoff
- Bot detection avoidance with stealth mode
- Rate limiting (2 req/sec per domain)
- Zero false positives

---

## ğŸ“¦ Setup

**Prerequisites:** Python 3.8+

```bash
bash setup.sh
```

This installs dependencies, Playwright browser, and creates necessary directories.

---

## ğŸš€ Usage

### Problem 1: Scrape Meeting Metadata

```bash
bash run.sh
```

Scrapes 6 government websites (Nov 20, 2024 - Nov 26, 2025):
- cityofventura.ca.gov/AgendaCenter
- bethlehem-pa.gov/Calendar
- lansdale.org/CivicMedia
- facebook.com/DauphinCountyPA/videos
- go.boarddocs.com/ca/acoe/Board.nsf/Public
- simbli.eboardsolutions.com (S=36030373)

**Output:** `outputs/problem1_complete_output.json` (saves after each domain)

### Custom Input

Create input file:
```json
{
  "start_date": "2024-01-01",
  "end_date": "2024-12-31",
  "base_urls": ["https://your-site.gov/meetings"]
}
```

Run:
```bash
python scraper.py scrape-meetings -i inputs/your_input.json -o outputs/your_output.json
```

### Problem 2: Resolve URLs

```bash
python scraper.py resolve-urls -i examples/problem2_input.json -o outputs/problem2_output.json
```

### Bonus Task: Universal Scraper

```bash
python scraper.py universal-scrape -i examples/bonus_input.json -o outputs/bonus_output.json
```

---

## ğŸ“‹ Input/Output

**Input:**
```json
{
  "start_date": "2024-11-20",
  "end_date": "2025-11-26",
  "base_urls": ["https://example.gov/meetings"]
}
```

**Output:**
```json
[
  {
    "base_url": "https://example.gov/meetings",
    "medias": [
      {
        "meeting_url": "https://www.youtube.com/watch?v=...",
        "agenda_url": "https://example.gov/agenda.pdf",
        "minutes_url": "https://example.gov/minutes.pdf",
        "title": "City Council Meeting",
        "date": "2024-11-20"
      }
    ]
  }
]
```

---

## ğŸ“ Project Structure

```
scraping/
â”œâ”€â”€ scraper.py              # CLI interface
â”œâ”€â”€ setup.sh                # Installation
â”œâ”€â”€ run.sh                  # Run Problem 1
â”œâ”€â”€ inputs/                 # Input JSON files
â”œâ”€â”€ outputs/                # Generated outputs (incremental saves)
â”œâ”€â”€ logs/                   # Application logs
â””â”€â”€ src/
    â”œâ”€â”€ core/               # Engine & browser management
    â”œâ”€â”€ extractors/         # Site-specific extraction logic
    â”œâ”€â”€ storage/            # Data models
    â””â”€â”€ utils/              # Helpers & logging
```

---

## ğŸ”§ Configuration

Edit `src/storage/models.py`:
- **Rate Limit**: `rate_limit=2` (requests/sec per domain)
- **Max Retries**: `max_retries=3`
- **Browser Timeout**: `timeout=60` (seconds)

---

## ğŸ› Troubleshooting

**Virtual environment:**
```bash
source .venv/Scripts/activate  # Windows
source .venv/bin/activate      # Linux/Mac
```

**Browser missing:**
```bash
playwright install chromium
```

---

## ğŸ¯ Assignment Coverage

âœ… Problem 1: Meeting metadata with date filtering  
âœ… Problem 2: Video/document URL resolution  
âœ… Bonus Task: Universal scraper (40+ sites)

---

**Note:** For ethical scraping of public government data only.
